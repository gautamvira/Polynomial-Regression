# Polynomial-Regression
Estimating coefficients for polynomial regression using gradient descent (GD)

## Procedure
A dataset is generated of N samples with two features: X and Y. A noise level is used to generate the Y, such that Y = cos(2πX) + Z, where Z is a zero mean gaussian variable with a variance, while X takes values (0, 1). The dataset is then fitted to a degree-d polynomial to estimate the coefficients of the polynomials. The coefficients are estimated using Gradient Descent. The estimated polynomials are used to find the predicted Y values for the training dataset. The Mean Square Error (MSE) is the metric used to evaluate the performance of the algorithm. The obtained coefficients are then used to predict Y values for another generated test set. The MSE of the test set serves as another metric. The gap between the MSEin and MSEout can be observed to evaluate the generalization of the regression model. To experiment with the algorithm, the aforementioned process is carried out for M trials and the results (including the estimated coefficients) are averaged to test against one other test set to evaluate the bias. The outputs – MSEin, MSEout, and MSEbias – serve as the main metrics to evaluate different configurations (sample size of the dataset, degree of the polynomial, noise level) of the model. These outputs are plotted for understanding and observing the model’s performance. Furthermore, the model was evaluated with and without weight decay regularization.

##Outputs
The graphs are plotted with the Ein (MSE training average), Eout (MSE testing avergage), and Ebias (MSE bias testing) along the Y-axis and the degree of the polynomial along the X-axis. Graphs are plotted for all combinations of N ∈ {2, 5, 10, 20, 50, 100, 200}, d ∈ {0, 1, 2, . . . , 20}, σ ∈ {0.01, 0.1, 1}. The Y-ranges of graphs could not be scaled to be the same for all configurations because some configurations have large errors whereas some configurations have very low errors, thus scaling them to have equal ranges would’ve have concealed the changes in graphs with low values or high peak errors would not have fitted in the graph.
